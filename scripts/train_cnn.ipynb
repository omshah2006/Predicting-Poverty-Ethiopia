{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "RANDOM_SEED = 7 # for reproducibility\n",
    "COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "\n",
    "# these relate to training the CNN to predict nightlights\n",
    "CNN_TRAIN_IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'cnn_images')\n",
    "CNN_SAVE_DIR = os.path.join(BASE_DIR, 'models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CNN_TRAIN_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(CNN_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "After doing this once, you can skip to the training if the script broke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actually downloaded: 11883, expected: 11650\n"
     ]
    }
   ],
   "source": [
    "df_download = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_locs.csv'))\n",
    "downloaded = os.listdir(os.path.join(COUNTRIES_DIR, 'ethiopia_2015', 'images'))\n",
    "print(f\"actually downloaded: {len(downloaded)}, expected: {len(df_download)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>total_hv</th>\n",
       "      <th>country</th>\n",
       "      <th>harvest_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.722773102424024_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.722773</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.737745023826016_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.737745</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.752716945228008_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.752717</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.76768886663_39.22483343759403_4.76768886663_...</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.7826607880319925_39.22483343759403_4.7676888...</td>\n",
       "      <td>4.782661</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  4.722773102424024_39.22483343759403_4.76768886...   4.722773  39.224833   \n",
       "1  4.737745023826016_39.22483343759403_4.76768886...   4.737745  39.224833   \n",
       "2  4.752716945228008_39.22483343759403_4.76768886...   4.752717  39.224833   \n",
       "3  4.76768886663_39.22483343759403_4.76768886663_...   4.767689  39.224833   \n",
       "4  4.7826607880319925_39.22483343759403_4.7676888...   4.782661  39.224833   \n",
       "\n",
       "   cluster_lat  cluster_lon    cons_pc  total_hv country  harvest_bin  \n",
       "0     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "1     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "2     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "3     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "4     4.767689    39.269749  14.111695    4200.0     eth            0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_download.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download['row'] = np.arange(len(df_download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['14.320643224665318_38.19946926442022_14.2885896726_38.210251919.png'\\n '9.195615362971115_42.41240281040326_9.23975778401_42.4419432943.png'\\n '9.582989156929402_39.824054101920815_9.61257094668_39.7830434463.png'\\n '8.148356535507192_38.65342651220573_8.16863199454_38.6464528783.png'\\n '9.284326164738976_42.25525822223033_9.2463064163_42.2173944859.png'\\n '7.249186660111342_40.59355581133207_7.25898773197_40.6146233206.png'\\n '10.023568448189675_39.18207081954763_10.0245110384_39.2131652933.png'\\n '8.75286951155489_35.5353786819388_8.7688653041_35.5671754136.png'\\n '13.20594658441797_39.160520820999785_13.2349577336_39.1634392625.png'\\n '10.606417152712877_39.93443713487593_10.5738928409_39.9354279996.png'\\n '12.39956340246899_38.740436439766775_12.4280735835_38.705318321.png'\\n '7.985155674774906_37.46579516942894_7.97698683396_37.4779072445.png'\\n '6.008658642208516_38.384688162963826_6.02435784991_38.3413616597.png'\\n '9.29755583312756_42.1813762917495_9.3102972075_42.1842178725.png'\\n '11.408195990885895_37.43130395787235_11.3744751246_37.4523245003.png'\\n '11.024214533135977_39.96734266825967_10.9878391908_39.9234074653.png'\\n '6.159729762943622_36.58507909637776_6.20010588939_36.5861907555.png'\\n '5.529834427318454_38.79268809550931_5.52570615347_38.7620666963.png'\\n '10.87023131439411_37.081909533439905_10.8293373184_37.064423275.png'\\n '11.064191593227884_37.03466643183701_11.0636624461_37.0703789795.png'\\n '9.65690123693412_34.50782772014847_9.62033298025_34.5342648788.png'\\n '9.507483555470806_41.67467536735902_9.47303240515_41.7186492241.png'\\n '7.767571227611068_38.326798708823986_7.79120996652_38.3295082817.png'\\n '9.703891995915617_34.72467637934179_9.73443000378_34.7285555289.png'\\n '14.128631276341283_37.52339253564873_14.0872350664_37.5015263838.png'\\n '6.67175231543629_37.417311072514494_6.70685847437_37.409545286.png'\\n '12.390354860886632_35.89590556185533_12.3910703535_35.9335894324.png'\\n '12.353343766018428_39.037529907088285_12.375944081_39.0057851612.png'\\n '8.878189315270225_37.89237451270116_8.84115434604_37.9135797978.png'\\n '7.484483261619122_36.4575899355716_7.47556744642_36.4429756569.png'\\n '10.12094729178578_34.67973249777745_10.081237992_34.6831901825.png'\\n '6.990053517569199_35.75117463067631_6.94902910992_35.772021814.png'\\n '9.38785528676221_36.24502309766505_9.36663445547_36.2748855694.png'\\n '9.369235451463195_42.182681542764875_9.33726350871_42.2004270507.png'\\n '8.634595003805973_40.604104126583906_8.65230864709_40.6178499401.png'\\n '6.235398520673456_36.609306485439554_6.2656349463_36.6109388136.png'\\n '7.475267837460208_37.60163727679521_7.51326045706_37.6461378355.png'\\n '8.689776153607824_37.94613454583499_8.72042840438_37.9114568164.png'\\n '13.01463609497561_39.36130843248668_13.01685124_39.3671636164.png'\\n '11.67971637184973_39.07208888649178_11.6549185473_39.0357534985.png'\\n '12.839373540000041_37.38403442422758_12.805251571_37.4183801156.png'\\n '11.339990154710906_38.250837069529595_11.3508873749_38.2271249275.png'\\n '6.937475881726001_37.6926148072324_6.90210116638_37.7348762189.png'\\n '6.980660273611457_40.342486999295616_6.98359796157_40.3522763184.png'\\n '11.976745791671663_39.36507623941874_11.991048262_39.3570736517.png'\\n '9.837037137205364_37.126038411298474_9.8440806253_37.1271346597.png'\\n '12.349669711285902_37.85565200936384_12.3059878852_37.8380133833.png'\\n '7.698176017474803_38.116077980269225_7.65816033645_38.0946319154.png'\\n '10.38973883746197_37.59941805830318_10.4216173585_37.5765488785.png'\\n '9.707772858878107_39.94587902740096_9.67897313862_39.913593504.png'\\n '8.358466342613408_33.911677635968424_8.40007079517_33.938508848.png'\\n '14.29635506153529_39.28897026138163_14.3192174691_39.2715992602.png'\\n '10.554694118451662_39.21694443602537_10.5685626516_39.2356643786.png'\\n '8.724056604819847_38.77949991111094_8.68349171525_38.8054367657.png'\\n '8.116883884822261_38.404342038265305_8.07578959014_38.4395969167.png'\\n '11.139270804748818_36.34564638314719_11.115608637_36.3763433187.png'\\n '5.600952043300193_37.619306469819435_5.60315524467_37.6030634072.png'\\n '13.435538468583779_37.08760587143473_13.4774390358_37.121337842.png'\\n '7.16473436368338_36.902102271184766_7.14637860111_36.8971397399.png'\\n '8.457865056989272_37.469137275140845_8.46646303095_37.4369214482.png'\\n '8.155370079409693_35.68197421668364_8.16979824749_35.6406321333.png'\\n '7.858177427626538_37.84028687897138_7.81991142387_37.828597498.png'\\n '11.45074801030703_39.843304280835554_11.4159600258_39.8485705676.png'\\n '11.63025136887795_39.627221160727686_11.6692064259_39.6566031821.png'\\n '13.785418457625134_37.45201047449755_13.7975010186_37.4518510509.png'\\n '7.6900640180446995_37.68551880938461_7.70538466173_37.6505389613.png'\\n '9.876120180163934_38.37515856436098_9.8912342367_38.3744314394.png'\\n '6.649530888086775_36.77082195863841_6.63095001102_36.7852027008.png'\\n '11.952909426045077_39.099328353310426_11.9625257933_39.098154379.png'\\n '8.783027688244244_36.44431317762557_8.74304517464_36.4844481911.png'\\n '11.397715447557337_37.08206040361391_11.3962743181_37.042616257.png'\\n '10.570677371682615_39.89119296774963_10.5883521237_39.9074958295.png'\\n '7.765783258492903_39.879085291229046_7.77573960381_39.8661143537.png'\\n '13.815845881847233_39.60080589416303_13.8014265472_39.6182529669.png'\\n '6.929545484902616_38.60190238516857_6.93084850884_38.595896045.png'\\n '9.356445403414554_42.29118767565655_9.33257557657_42.2485029939.png'\\n '6.303735855531313_35.244334049182505_6.2600677475_35.2645547968.png'\\n '8.732142657069963_39.22166091309378_8.72717898314_39.1876998149.png'\\n '9.376288154860951_36.246908965292725_9.39137371981_36.2194348147.png'\\n '14.254047202193322_38.5742950257408_14.2834679193_38.5730157222.png'\\n '13.531283462216875_37.624564793622596_13.5160575022_37.6273155648.png'\\n '11.631750901080366_37.13329409836706_11.6514708203_37.1032812474.png'\\n '7.946845367710899_38.15251518798305_7.98501581104_38.1539348643.png'\\n '7.407703917691876_37.89733240355338_7.37676330298_37.8935648714.png'\\n '7.879663699554462_36.102613480606244_7.88005862562_36.0983250614.png'\\n '11.68291162853339_37.57953799150041_11.6890721348_37.6074550557.png'\\n '10.154232032557003_38.94147582958025_10.1771510236_38.9727796823.png'\\n '4.803225877563182_39.259303665466085_4.76768886663_39.2697492018.png'\\n '9.032557934410358_35.08123145546841_9.01530115929_35.046540828.png'\\n '12.952360556878743_36.819640632348815_12.9534149289_36.8314382163.png'\\n '5.613255585937507_37.38200463617132_5.63928393085_37.3823169626.png'\\n '7.466987789182859_38.93221537740917_7.42843060501_38.9573869302.png'\\n '9.474535664573711_34.39444171580353_9.47651243141_34.4209015528.png'\\n '7.380026576035127_38.12200467541612_7.40568344221_38.0810753873.png'\\n '10.68604430150243_39.928263517833635_10.7206898499_39.8860291278.png'\\n '10.462652314453155_38.204316327084065_10.4180717415_38.1697121297.png'\\n '10.960485799860338_39.91260117468845_11.003906691_39.9387898351.png'\\n '7.183242724762132_35.4650630179759_7.14547506346_35.4611988078.png'\\n '10.577041179444507_38.61560067169704_10.5792188385_38.6062533111.png'\\n '12.662856812273668_39.657162976948314_12.6231333276_39.6516820917.png'\\n '13.359128369990282_37.77483138187008_13.3722274393_37.7898736298.png'\\n '9.81859478709032_37.52033033084536_9.79007481406_37.5059416726.png'\\n '14.122587099958926_39.22712438972653_14.1583566438_39.2258474475.png'\\n '11.877213011083516_39.47825275580846_11.9048460332_39.4494717129.png'\\n '9.640986764476684_42.044618103157_9.60298076521_42.0803290584.png'\\n '7.075013662138791_37.106682400009966_7.09924325001_37.128257018.png'\\n '10.000045629879343_37.65729269582314_9.99190626942_37.6925527139.png'\\n '9.120020632105373_35.61308812773123_9.07702977605_35.6156340346.png'\\n '5.962603206788262_37.39408676592567_5.98817082582_37.4387863255.png'\\n '10.000778737067458_38.22470937635843_10.0165864149_38.2492265926.png'\\n '6.278862726268314_37.47641736238545_6.29109687243_37.4818442988.png'\\n '9.510534503475089_39.5937123014601_9.55408199803_39.5793387065.png'\\n '6.943601749350098_36.46956563534273_6.98589410147_36.4255203181.png'\\n '6.789520519689621_35.89138010044883_6.80492958256_35.8646146207.png'\\n '7.018883077840177_39.18744176074608_7.00349013971_39.1624463866.png'\\n '8.072612969186808_39.011055522581316_8.08842299138_39.0349251986.png'\\n '6.919605086710808_37.27466013843835_6.94302150261_37.2950167052.png'\\n '14.023114760002972_38.64877344749552_13.985946938_38.6492990176.png'\\n '14.042125829768986_39.015890952647716_14.0859773206_38.9755077144.png'\\n '7.2465433619060216_37.76725133119854_7.28374522639_37.7571481782.png'\\n '7.434914588080047_37.90726832120719_7.442807492_37.8659104876.png'\\n '14.340826796533074_37.91226498037486_14.353816185_37.890876313.png'\\n '9.741024621800698_37.05382714813409_9.7591387282_37.044814049.png'\\n '8.156681845581629_34.194032404283455_8.19726994714_34.2016617219.png'\\n '5.276061586363268_37.403818158414_5.25295513188_37.4271768268.png'\\n '9.416036459080622_38.338444299335556_9.3723549327_38.3223627848.png'\\n '12.005324376667224_37.82842482681568_12.0498233904_37.8003237608.png'\\n '11.071490383488086_40.03841737111664_11.1136181517_40.017211804.png'\\n '7.14316387587062_37.93641146183556_7.17430039499_37.9492676831.png'\\n '9.042798175908402_39.00313167655598_9.00397364652_39.0027426232.png'\\n '7.704141476724522_35.83818136522253_7.67211701378_35.8400122926.png'\\n '8.209795314675427_36.50507949271459_8.18930636005_36.4699847397.png'\\n '12.528444246450334_38.80111849330211_12.5144435035_38.8249840847.png'\\n '9.518318174186334_42.0552908346398_9.55091666159_42.0823653656.png'\\n '8.162248606206408_37.941825532902755_8.17949664228_37.9272178152.png'\\n '7.232267985085153_38.11834137739759_7.27673837537_38.1157382755.png'\\n '7.618210706648142_39.82742433937443_7.58861044429_39.7945944298.png'\\n '7.472454871317324_41.04204849349551_7.43667493729_41.0005629905.png'\\n '8.689300354318732_36.61245985188273_8.6536780825_36.6077474888.png'\\n '11.169760264840455_36.96973591362082_11.1913400617_36.9496969313.png'\\n '10.932631834860894_40.01699291712314_10.9436292122_40.0054371148.png'\\n '14.179074902196321_36.47577879753096_14.1819914938_36.4799930893.png'\\n '12.725663370639749_38.99091700241729_12.7580639926_38.9938699775.png'\\n '10.905834772665134_36.61316555615136_10.9370696143_36.6547551047.png'\\n '9.416922242496845_42.892474272314814_9.40053953262_42.8585260119.png'\\n '11.216007777918852_38.31393914647674_11.2385732357_38.311340877.png'\\n '9.819715621973781_34.924703736061886_9.83705860887_34.9150151529.png'\\n '13.691002692198989_37.42890639363379_13.6709932967_37.4064256501.png'\\n '7.382897927771889_38.7803569322611_7.34918791893_38.8049340076.png'\\n '6.617725439059774_37.4847736932235_6.61699649052_37.4846255397.png'\\n '5.964067004826405_37.13544874941813_5.94989088571_37.1552324163.png'\\n '12.424690733059165_39.062826618487435_12.3989125709_39.0897466901.png'\\n '13.214871184820788_37.83231193440751_13.2058110304_37.7876552215.png'\\n '14.093169803757748_38.01959852588791_14.0862760222_37.9831865445.png'\\n '5.788478375744806_37.834505643270404_5.74709706037_37.8508868358.png'\\n '6.381991180433635_36.546591293679825_6.36391514169_36.5892168406.png'\\n '13.848798848541978_38.61654309382989_13.8713387734_38.6366907016.png'\\n '10.873456659684667_38.028816906233544_10.9070459818_38.0365174999.png'\\n '9.313527475543154_35.536207462771436_9.35810274536_35.5751653852.png'\\n '12.811835379955227_36.88666242984996_12.8017155321_36.93031443.png'\\n '13.745533380201982_37.40402707651948_13.731570436_37.3672533162.png'\\n '10.491306972819793_39.775475673008124_10.5281537836_39.8131068222.png'\\n '6.3238552093052425_36.58844022617407_6.33301035552_36.6032685349.png'\\n '10.19987010748597_35.28768629821292_10.1813677297_35.281505142.png'\\n '13.61865834231656_38.09342551624342_13.642517176_38.1191822345.png'\\n '8.434655533487126_33.44518714729208_8.39200458575_33.4683567701.png'\\n '11.047076595253573_39.74221321077062_11.0874300942_39.7843913054.png'\\n '14.279814810744334_39.10106500944313_14.3007959467_39.0594892637.png'\\n '11.565831090555472_41.55117566121139_11.5278035382_41.5207097044.png'\\n '5.857101340791498_37.88224071810914_5.85184911518_37.8832189758.png'\\n '5.524773649013582_37.55879752106334_5.49534488804_37.5518429316.png'\\n '7.007109808030955_37.32276734703835_7.03607701317_37.3092790736.png'\\n '6.131205263985945_36.67143670930249_6.13630868631_36.6759763471.png'\\n '7.393274742352849_37.59082538966872_7.38160282799_37.6033985811.png'\\n '6.471053315878792_39.889496908306036_6.45050353832_39.8802730059.png'\\n '7.520503289954277_37.04971693916079_7.54783077574_37.0818248622.png'\\n '13.962051491582736_39.491257876362326_13.9843705066_39.5331294187.png'\\n '10.592168994819675_37.006362136908095_10.5773759639_37.0449675094.png'\\n '9.760608874340925_34.783235784324475_9.74422788621_34.7872968911.png'\\n '6.771206468638847_37.58229817632278_6.78301858962_37.5509812536.png'\\n '13.8558919829178_39.745809181325555_13.895387614_39.7873002106.png'\\n '5.282600347989948_37.47458759950972_5.29947726643_37.4826182904.png'\\n '8.981089643684303_38.66893346605798_8.97089097863_38.6245563425.png'\\n '8.605603215314668_38.17804161987013_8.6361010406_38.1519350254.png'\\n '12.775518625156492_39.32373094646282_12.7826268158_39.3068867968.png'\\n '12.597884560132892_39.41770066512433_12.6209662316_39.4244520175.png'\\n '4.800503282270729_36.04461014531233_4.8070976028_36.0818398582.png'\\n '7.183230419569102_36.83175055830495_7.15974968202_36.836041539.png'\\n '9.03738378541297_40.74555712509749_9.0093694062_40.7218752036.png'\\n '13.292023147090351_39.467639287298844_13.2820240216_39.4405203839.png'\\n '8.695111308198905_35.62064212344642_8.66161555833_35.6426976235.png'\\n '7.05685951827468_36.6606175807447_7.09517484082_36.6553017363.png'\\n '11.855994783059895_39.148910291292324_11.8139982171_39.1404087668.png'\\n '13.867798008116122_37.38238077313457_13.8351102558_37.4103917923.png'\\n '9.875547809412602_39.52049057144623_9.89048905403_39.4845296.png'\\n '11.678984938071837_38.442879690793184_11.6454398842_38.4188571016.png'\\n '5.617157372069069_38.28910563452904_5.59568261612_38.2936192427.png'\\n '6.342529977450863_38.717877580826276_6.37589338272_38.7269447069.png'\\n '12.33268382055332_38.48596934405761_12.3562967332_38.4524416164.png'\\n '8.600140384581822_37.09661957013346_8.64302754866_37.0632145326.png'\\n '7.277501690670776_36.639026142354446_7.31318183469_36.5951905108.png'\\n '9.861607442137064_36.381677911330506_9.84708661386_36.3422982077.png'\\n '6.973555775382949_37.92648004548794_6.94992604668_37.8864940524.png'\\n '10.117221863047726_39.29051031779241_10.1255685035_39.3173063282.png'\\n '7.099181992164982_36.477507099123855_7.11090917192_36.4669773812.png'\\n '12.84142281795865_36.964942133060376_12.8780575269_36.9851395735.png'\\n '8.119121624918696_38.803685989425595_8.11332653211_38.7753045688.png'\\n '7.912551556446316_37.56233314454296_7.8891255011_37.5456591429.png'\\n '11.330726088582553_36.31485868313738_11.3323287202_36.2720183518.png'\\n '12.371614904365915_37.67462314982102_12.3384962559_37.6750209615.png'\\n '10.622545688677404_37.79052646146384_10.5794319268_37.798498412.png'\\n '11.397626606589435_39.42135778527508_11.3563674371_39.4349241782.png'\\n '5.813693187186211_36.5847781401078_5.83633941337_36.6070302097.png'\\n '10.810317092888138_37.17743644272347_10.7927763733_37.144541492.png'\\n '6.763570354799652_38.50064872198596_6.80310210938_38.5126355838.png'\\n '8.163399031101688_38.21464934532922_8.13327890849_38.2086730522.png'\\n '7.13490998923246_39.80841903430633_7.1643297276_39.8203710541.png'\\n '7.720229166287125_37.46930089436367_7.73169598877_37.4985838007.png'\\n '6.425857571746519_38.851018037326256_6.39898337786_38.8768980886.png'\\n '5.938568310105963_38.19047832525463_5.98301240509_38.1616652609.png'\\n '4.89708197111467_39.16957676118547_4.87905466671_39.1953787271.png'\\n '7.455742331582134_35.893806690762894_7.44867719122_35.868074501.png'\\n '5.673022349006429_37.40831290715781_5.64655886803_37.3818910811.png'\\n '11.261362454955092_36.93252494596605_11.2828210609_36.9596879306.png'\\n '8.6111917485525_34.64875297524153_8.61492078832_34.6514363264.png'\\n '9.307858856086883_42.128400463699045_9.26445855436_42.1477441163.png'\\n '10.509797101551573_36.04699000591686_10.5023759921_36.0048077152.png'\\n '7.279945155123306_38.60347814429366_7.26850368689_38.6020916798.png'\\n '9.771481624526741_38.685244550980315_9.77979055862_38.658246372.png'\\n '9.03552989013435_36.3892161109143_9.0308423142_36.4037942076.png'\\n '5.571971838020388_37.84259265170874_5.5541668341_37.8416513316.png'\\n '10.553063274408704_37.43003724754838_10.5892768292_37.4615982338.png'\\n '10.978674260005247_38.2677742751574_10.9551945389_38.2846965084.png'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3991/3441888405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx_not_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_not_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['14.320643224665318_38.19946926442022_14.2885896726_38.210251919.png'\\n '9.195615362971115_42.41240281040326_9.23975778401_42.4419432943.png'\\n '9.582989156929402_39.824054101920815_9.61257094668_39.7830434463.png'\\n '8.148356535507192_38.65342651220573_8.16863199454_38.6464528783.png'\\n '9.284326164738976_42.25525822223033_9.2463064163_42.2173944859.png'\\n '7.249186660111342_40.59355581133207_7.25898773197_40.6146233206.png'\\n '10.023568448189675_39.18207081954763_10.0245110384_39.2131652933.png'\\n '8.75286951155489_35.5353786819388_8.7688653041_35.5671754136.png'\\n '13.20594658441797_39.160520820999785_13.2349577336_39.1634392625.png'\\n '10.606417152712877_39.93443713487593_10.5738928409_39.9354279996.png'\\n '12.39956340246899_38.740436439766775_12.4280735835_38.705318321.png'\\n '7.985155674774906_37.46579516942894_7.97698683396_37.4779072445.png'\\n '6.008658642208516_38.384688162963826_6.02435784991_38.3413616597.png'\\n '9.29755583312756_42.1813762917495_9.3102972075_42.1842178725.png'\\n '11.408195990885895_37.43130395787235_11.3744751246_37.4523245003.png'\\n '11.024214533135977_39.96734266825967_10.9878391908_39.9234074653.png'\\n '6.159729762943622_36.58507909637776_6.20010588939_36.5861907555.png'\\n '5.529834427318454_38.79268809550931_5.52570615347_38.7620666963.png'\\n '10.87023131439411_37.081909533439905_10.8293373184_37.064423275.png'\\n '11.064191593227884_37.03466643183701_11.0636624461_37.0703789795.png'\\n '9.65690123693412_34.50782772014847_9.62033298025_34.5342648788.png'\\n '9.507483555470806_41.67467536735902_9.47303240515_41.7186492241.png'\\n '7.767571227611068_38.326798708823986_7.79120996652_38.3295082817.png'\\n '9.703891995915617_34.72467637934179_9.73443000378_34.7285555289.png'\\n '14.128631276341283_37.52339253564873_14.0872350664_37.5015263838.png'\\n '6.67175231543629_37.417311072514494_6.70685847437_37.409545286.png'\\n '12.390354860886632_35.89590556185533_12.3910703535_35.9335894324.png'\\n '12.353343766018428_39.037529907088285_12.375944081_39.0057851612.png'\\n '8.878189315270225_37.89237451270116_8.84115434604_37.9135797978.png'\\n '7.484483261619122_36.4575899355716_7.47556744642_36.4429756569.png'\\n '10.12094729178578_34.67973249777745_10.081237992_34.6831901825.png'\\n '6.990053517569199_35.75117463067631_6.94902910992_35.772021814.png'\\n '9.38785528676221_36.24502309766505_9.36663445547_36.2748855694.png'\\n '9.369235451463195_42.182681542764875_9.33726350871_42.2004270507.png'\\n '8.634595003805973_40.604104126583906_8.65230864709_40.6178499401.png'\\n '6.235398520673456_36.609306485439554_6.2656349463_36.6109388136.png'\\n '7.475267837460208_37.60163727679521_7.51326045706_37.6461378355.png'\\n '8.689776153607824_37.94613454583499_8.72042840438_37.9114568164.png'\\n '13.01463609497561_39.36130843248668_13.01685124_39.3671636164.png'\\n '11.67971637184973_39.07208888649178_11.6549185473_39.0357534985.png'\\n '12.839373540000041_37.38403442422758_12.805251571_37.4183801156.png'\\n '11.339990154710906_38.250837069529595_11.3508873749_38.2271249275.png'\\n '6.937475881726001_37.6926148072324_6.90210116638_37.7348762189.png'\\n '6.980660273611457_40.342486999295616_6.98359796157_40.3522763184.png'\\n '11.976745791671663_39.36507623941874_11.991048262_39.3570736517.png'\\n '9.837037137205364_37.126038411298474_9.8440806253_37.1271346597.png'\\n '12.349669711285902_37.85565200936384_12.3059878852_37.8380133833.png'\\n '7.698176017474803_38.116077980269225_7.65816033645_38.0946319154.png'\\n '10.38973883746197_37.59941805830318_10.4216173585_37.5765488785.png'\\n '9.707772858878107_39.94587902740096_9.67897313862_39.913593504.png'\\n '8.358466342613408_33.911677635968424_8.40007079517_33.938508848.png'\\n '14.29635506153529_39.28897026138163_14.3192174691_39.2715992602.png'\\n '10.554694118451662_39.21694443602537_10.5685626516_39.2356643786.png'\\n '8.724056604819847_38.77949991111094_8.68349171525_38.8054367657.png'\\n '8.116883884822261_38.404342038265305_8.07578959014_38.4395969167.png'\\n '11.139270804748818_36.34564638314719_11.115608637_36.3763433187.png'\\n '5.600952043300193_37.619306469819435_5.60315524467_37.6030634072.png'\\n '13.435538468583779_37.08760587143473_13.4774390358_37.121337842.png'\\n '7.16473436368338_36.902102271184766_7.14637860111_36.8971397399.png'\\n '8.457865056989272_37.469137275140845_8.46646303095_37.4369214482.png'\\n '8.155370079409693_35.68197421668364_8.16979824749_35.6406321333.png'\\n '7.858177427626538_37.84028687897138_7.81991142387_37.828597498.png'\\n '11.45074801030703_39.843304280835554_11.4159600258_39.8485705676.png'\\n '11.63025136887795_39.627221160727686_11.6692064259_39.6566031821.png'\\n '13.785418457625134_37.45201047449755_13.7975010186_37.4518510509.png'\\n '7.6900640180446995_37.68551880938461_7.70538466173_37.6505389613.png'\\n '9.876120180163934_38.37515856436098_9.8912342367_38.3744314394.png'\\n '6.649530888086775_36.77082195863841_6.63095001102_36.7852027008.png'\\n '11.952909426045077_39.099328353310426_11.9625257933_39.098154379.png'\\n '8.783027688244244_36.44431317762557_8.74304517464_36.4844481911.png'\\n '11.397715447557337_37.08206040361391_11.3962743181_37.042616257.png'\\n '10.570677371682615_39.89119296774963_10.5883521237_39.9074958295.png'\\n '7.765783258492903_39.879085291229046_7.77573960381_39.8661143537.png'\\n '13.815845881847233_39.60080589416303_13.8014265472_39.6182529669.png'\\n '6.929545484902616_38.60190238516857_6.93084850884_38.595896045.png'\\n '9.356445403414554_42.29118767565655_9.33257557657_42.2485029939.png'\\n '6.303735855531313_35.244334049182505_6.2600677475_35.2645547968.png'\\n '8.732142657069963_39.22166091309378_8.72717898314_39.1876998149.png'\\n '9.376288154860951_36.246908965292725_9.39137371981_36.2194348147.png'\\n '14.254047202193322_38.5742950257408_14.2834679193_38.5730157222.png'\\n '13.531283462216875_37.624564793622596_13.5160575022_37.6273155648.png'\\n '11.631750901080366_37.13329409836706_11.6514708203_37.1032812474.png'\\n '7.946845367710899_38.15251518798305_7.98501581104_38.1539348643.png'\\n '7.407703917691876_37.89733240355338_7.37676330298_37.8935648714.png'\\n '7.879663699554462_36.102613480606244_7.88005862562_36.0983250614.png'\\n '11.68291162853339_37.57953799150041_11.6890721348_37.6074550557.png'\\n '10.154232032557003_38.94147582958025_10.1771510236_38.9727796823.png'\\n '4.803225877563182_39.259303665466085_4.76768886663_39.2697492018.png'\\n '9.032557934410358_35.08123145546841_9.01530115929_35.046540828.png'\\n '12.952360556878743_36.819640632348815_12.9534149289_36.8314382163.png'\\n '5.613255585937507_37.38200463617132_5.63928393085_37.3823169626.png'\\n '7.466987789182859_38.93221537740917_7.42843060501_38.9573869302.png'\\n '9.474535664573711_34.39444171580353_9.47651243141_34.4209015528.png'\\n '7.380026576035127_38.12200467541612_7.40568344221_38.0810753873.png'\\n '10.68604430150243_39.928263517833635_10.7206898499_39.8860291278.png'\\n '10.462652314453155_38.204316327084065_10.4180717415_38.1697121297.png'\\n '10.960485799860338_39.91260117468845_11.003906691_39.9387898351.png'\\n '7.183242724762132_35.4650630179759_7.14547506346_35.4611988078.png'\\n '10.577041179444507_38.61560067169704_10.5792188385_38.6062533111.png'\\n '12.662856812273668_39.657162976948314_12.6231333276_39.6516820917.png'\\n '13.359128369990282_37.77483138187008_13.3722274393_37.7898736298.png'\\n '9.81859478709032_37.52033033084536_9.79007481406_37.5059416726.png'\\n '14.122587099958926_39.22712438972653_14.1583566438_39.2258474475.png'\\n '11.877213011083516_39.47825275580846_11.9048460332_39.4494717129.png'\\n '9.640986764476684_42.044618103157_9.60298076521_42.0803290584.png'\\n '7.075013662138791_37.106682400009966_7.09924325001_37.128257018.png'\\n '10.000045629879343_37.65729269582314_9.99190626942_37.6925527139.png'\\n '9.120020632105373_35.61308812773123_9.07702977605_35.6156340346.png'\\n '5.962603206788262_37.39408676592567_5.98817082582_37.4387863255.png'\\n '10.000778737067458_38.22470937635843_10.0165864149_38.2492265926.png'\\n '6.278862726268314_37.47641736238545_6.29109687243_37.4818442988.png'\\n '9.510534503475089_39.5937123014601_9.55408199803_39.5793387065.png'\\n '6.943601749350098_36.46956563534273_6.98589410147_36.4255203181.png'\\n '6.789520519689621_35.89138010044883_6.80492958256_35.8646146207.png'\\n '7.018883077840177_39.18744176074608_7.00349013971_39.1624463866.png'\\n '8.072612969186808_39.011055522581316_8.08842299138_39.0349251986.png'\\n '6.919605086710808_37.27466013843835_6.94302150261_37.2950167052.png'\\n '14.023114760002972_38.64877344749552_13.985946938_38.6492990176.png'\\n '14.042125829768986_39.015890952647716_14.0859773206_38.9755077144.png'\\n '7.2465433619060216_37.76725133119854_7.28374522639_37.7571481782.png'\\n '7.434914588080047_37.90726832120719_7.442807492_37.8659104876.png'\\n '14.340826796533074_37.91226498037486_14.353816185_37.890876313.png'\\n '9.741024621800698_37.05382714813409_9.7591387282_37.044814049.png'\\n '8.156681845581629_34.194032404283455_8.19726994714_34.2016617219.png'\\n '5.276061586363268_37.403818158414_5.25295513188_37.4271768268.png'\\n '9.416036459080622_38.338444299335556_9.3723549327_38.3223627848.png'\\n '12.005324376667224_37.82842482681568_12.0498233904_37.8003237608.png'\\n '11.071490383488086_40.03841737111664_11.1136181517_40.017211804.png'\\n '7.14316387587062_37.93641146183556_7.17430039499_37.9492676831.png'\\n '9.042798175908402_39.00313167655598_9.00397364652_39.0027426232.png'\\n '7.704141476724522_35.83818136522253_7.67211701378_35.8400122926.png'\\n '8.209795314675427_36.50507949271459_8.18930636005_36.4699847397.png'\\n '12.528444246450334_38.80111849330211_12.5144435035_38.8249840847.png'\\n '9.518318174186334_42.0552908346398_9.55091666159_42.0823653656.png'\\n '8.162248606206408_37.941825532902755_8.17949664228_37.9272178152.png'\\n '7.232267985085153_38.11834137739759_7.27673837537_38.1157382755.png'\\n '7.618210706648142_39.82742433937443_7.58861044429_39.7945944298.png'\\n '7.472454871317324_41.04204849349551_7.43667493729_41.0005629905.png'\\n '8.689300354318732_36.61245985188273_8.6536780825_36.6077474888.png'\\n '11.169760264840455_36.96973591362082_11.1913400617_36.9496969313.png'\\n '10.932631834860894_40.01699291712314_10.9436292122_40.0054371148.png'\\n '14.179074902196321_36.47577879753096_14.1819914938_36.4799930893.png'\\n '12.725663370639749_38.99091700241729_12.7580639926_38.9938699775.png'\\n '10.905834772665134_36.61316555615136_10.9370696143_36.6547551047.png'\\n '9.416922242496845_42.892474272314814_9.40053953262_42.8585260119.png'\\n '11.216007777918852_38.31393914647674_11.2385732357_38.311340877.png'\\n '9.819715621973781_34.924703736061886_9.83705860887_34.9150151529.png'\\n '13.691002692198989_37.42890639363379_13.6709932967_37.4064256501.png'\\n '7.382897927771889_38.7803569322611_7.34918791893_38.8049340076.png'\\n '6.617725439059774_37.4847736932235_6.61699649052_37.4846255397.png'\\n '5.964067004826405_37.13544874941813_5.94989088571_37.1552324163.png'\\n '12.424690733059165_39.062826618487435_12.3989125709_39.0897466901.png'\\n '13.214871184820788_37.83231193440751_13.2058110304_37.7876552215.png'\\n '14.093169803757748_38.01959852588791_14.0862760222_37.9831865445.png'\\n '5.788478375744806_37.834505643270404_5.74709706037_37.8508868358.png'\\n '6.381991180433635_36.546591293679825_6.36391514169_36.5892168406.png'\\n '13.848798848541978_38.61654309382989_13.8713387734_38.6366907016.png'\\n '10.873456659684667_38.028816906233544_10.9070459818_38.0365174999.png'\\n '9.313527475543154_35.536207462771436_9.35810274536_35.5751653852.png'\\n '12.811835379955227_36.88666242984996_12.8017155321_36.93031443.png'\\n '13.745533380201982_37.40402707651948_13.731570436_37.3672533162.png'\\n '10.491306972819793_39.775475673008124_10.5281537836_39.8131068222.png'\\n '6.3238552093052425_36.58844022617407_6.33301035552_36.6032685349.png'\\n '10.19987010748597_35.28768629821292_10.1813677297_35.281505142.png'\\n '13.61865834231656_38.09342551624342_13.642517176_38.1191822345.png'\\n '8.434655533487126_33.44518714729208_8.39200458575_33.4683567701.png'\\n '11.047076595253573_39.74221321077062_11.0874300942_39.7843913054.png'\\n '14.279814810744334_39.10106500944313_14.3007959467_39.0594892637.png'\\n '11.565831090555472_41.55117566121139_11.5278035382_41.5207097044.png'\\n '5.857101340791498_37.88224071810914_5.85184911518_37.8832189758.png'\\n '5.524773649013582_37.55879752106334_5.49534488804_37.5518429316.png'\\n '7.007109808030955_37.32276734703835_7.03607701317_37.3092790736.png'\\n '6.131205263985945_36.67143670930249_6.13630868631_36.6759763471.png'\\n '7.393274742352849_37.59082538966872_7.38160282799_37.6033985811.png'\\n '6.471053315878792_39.889496908306036_6.45050353832_39.8802730059.png'\\n '7.520503289954277_37.04971693916079_7.54783077574_37.0818248622.png'\\n '13.962051491582736_39.491257876362326_13.9843705066_39.5331294187.png'\\n '10.592168994819675_37.006362136908095_10.5773759639_37.0449675094.png'\\n '9.760608874340925_34.783235784324475_9.74422788621_34.7872968911.png'\\n '6.771206468638847_37.58229817632278_6.78301858962_37.5509812536.png'\\n '13.8558919829178_39.745809181325555_13.895387614_39.7873002106.png'\\n '5.282600347989948_37.47458759950972_5.29947726643_37.4826182904.png'\\n '8.981089643684303_38.66893346605798_8.97089097863_38.6245563425.png'\\n '8.605603215314668_38.17804161987013_8.6361010406_38.1519350254.png'\\n '12.775518625156492_39.32373094646282_12.7826268158_39.3068867968.png'\\n '12.597884560132892_39.41770066512433_12.6209662316_39.4244520175.png'\\n '4.800503282270729_36.04461014531233_4.8070976028_36.0818398582.png'\\n '7.183230419569102_36.83175055830495_7.15974968202_36.836041539.png'\\n '9.03738378541297_40.74555712509749_9.0093694062_40.7218752036.png'\\n '13.292023147090351_39.467639287298844_13.2820240216_39.4405203839.png'\\n '8.695111308198905_35.62064212344642_8.66161555833_35.6426976235.png'\\n '7.05685951827468_36.6606175807447_7.09517484082_36.6553017363.png'\\n '11.855994783059895_39.148910291292324_11.8139982171_39.1404087668.png'\\n '13.867798008116122_37.38238077313457_13.8351102558_37.4103917923.png'\\n '9.875547809412602_39.52049057144623_9.89048905403_39.4845296.png'\\n '11.678984938071837_38.442879690793184_11.6454398842_38.4188571016.png'\\n '5.617157372069069_38.28910563452904_5.59568261612_38.2936192427.png'\\n '6.342529977450863_38.717877580826276_6.37589338272_38.7269447069.png'\\n '12.33268382055332_38.48596934405761_12.3562967332_38.4524416164.png'\\n '8.600140384581822_37.09661957013346_8.64302754866_37.0632145326.png'\\n '7.277501690670776_36.639026142354446_7.31318183469_36.5951905108.png'\\n '9.861607442137064_36.381677911330506_9.84708661386_36.3422982077.png'\\n '6.973555775382949_37.92648004548794_6.94992604668_37.8864940524.png'\\n '10.117221863047726_39.29051031779241_10.1255685035_39.3173063282.png'\\n '7.099181992164982_36.477507099123855_7.11090917192_36.4669773812.png'\\n '12.84142281795865_36.964942133060376_12.8780575269_36.9851395735.png'\\n '8.119121624918696_38.803685989425595_8.11332653211_38.7753045688.png'\\n '7.912551556446316_37.56233314454296_7.8891255011_37.5456591429.png'\\n '11.330726088582553_36.31485868313738_11.3323287202_36.2720183518.png'\\n '12.371614904365915_37.67462314982102_12.3384962559_37.6750209615.png'\\n '10.622545688677404_37.79052646146384_10.5794319268_37.798498412.png'\\n '11.397626606589435_39.42135778527508_11.3563674371_39.4349241782.png'\\n '5.813693187186211_36.5847781401078_5.83633941337_36.6070302097.png'\\n '10.810317092888138_37.17743644272347_10.7927763733_37.144541492.png'\\n '6.763570354799652_38.50064872198596_6.80310210938_38.5126355838.png'\\n '8.163399031101688_38.21464934532922_8.13327890849_38.2086730522.png'\\n '7.13490998923246_39.80841903430633_7.1643297276_39.8203710541.png'\\n '7.720229166287125_37.46930089436367_7.73169598877_37.4985838007.png'\\n '6.425857571746519_38.851018037326256_6.39898337786_38.8768980886.png'\\n '5.938568310105963_38.19047832525463_5.98301240509_38.1616652609.png'\\n '4.89708197111467_39.16957676118547_4.87905466671_39.1953787271.png'\\n '7.455742331582134_35.893806690762894_7.44867719122_35.868074501.png'\\n '5.673022349006429_37.40831290715781_5.64655886803_37.3818910811.png'\\n '11.261362454955092_36.93252494596605_11.2828210609_36.9596879306.png'\\n '8.6111917485525_34.64875297524153_8.61492078832_34.6514363264.png'\\n '9.307858856086883_42.128400463699045_9.26445855436_42.1477441163.png'\\n '10.509797101551573_36.04699000591686_10.5023759921_36.0048077152.png'\\n '7.279945155123306_38.60347814429366_7.26850368689_38.6020916798.png'\\n '9.771481624526741_38.685244550980315_9.77979055862_38.658246372.png'\\n '9.03552989013435_36.3892161109143_9.0308423142_36.4037942076.png'\\n '5.571971838020388_37.84259265170874_5.5541668341_37.8416513316.png'\\n '10.553063274408704_37.43003724754838_10.5892768292_37.4615982338.png'\\n '10.978674260005247_38.2677742751574_10.9551945389_38.2846965084.png'] not found in axis\""
     ]
    }
   ],
   "source": [
    "idx_not_download = df_download.set_index('image_name').drop(downloaded)['row'].values.tolist()\n",
    "df_download.drop(idx_not_download, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download.drop('row', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5236051502145923, 0.2145922746781116, 0.26180257510729615)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the distribution\n",
    "(df_download['harvest_bin']==0).mean(), (df_download['harvest_bin']==1).mean(), (df_download['harvest_bin']==2).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split images into train/valid.\n",
    "Each cluster will contribute 80% of images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>total_hv</th>\n",
       "      <th>country</th>\n",
       "      <th>harvest_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.722773102424024_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.722773</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.737745023826016_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.737745</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.752716945228008_39.22483343759403_4.76768886...</td>\n",
       "      <td>4.752717</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.76768886663_39.22483343759403_4.76768886663_...</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.7826607880319925_39.22483343759403_4.7676888...</td>\n",
       "      <td>4.782661</td>\n",
       "      <td>39.224833</td>\n",
       "      <td>4.767689</td>\n",
       "      <td>39.269749</td>\n",
       "      <td>14.111695</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>eth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  4.722773102424024_39.22483343759403_4.76768886...   4.722773  39.224833   \n",
       "1  4.737745023826016_39.22483343759403_4.76768886...   4.737745  39.224833   \n",
       "2  4.752716945228008_39.22483343759403_4.76768886...   4.752717  39.224833   \n",
       "3  4.76768886663_39.22483343759403_4.76768886663_...   4.767689  39.224833   \n",
       "4  4.7826607880319925_39.22483343759403_4.7676888...   4.782661  39.224833   \n",
       "\n",
       "   cluster_lat  cluster_lon    cons_pc  total_hv country  harvest_bin  \n",
       "0     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "1     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "2     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "3     4.767689    39.269749  14.111695    4200.0     eth            0  \n",
       "4     4.767689    39.269749  14.111695    4200.0     eth            0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_download.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download['is_train'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "groups = df_download.groupby(['cluster_lat', 'cluster_lon'])\n",
    "for _, g in groups:\n",
    "    n_ims = len(g)\n",
    "    n_train = int(0.8 * n_ims)\n",
    "    n_valid = n_ims - n_train\n",
    "    valid_choices = np.random.choice(np.arange(n_ims), replace=False, size=n_valid).tolist()\n",
    "    current_index = g.index\n",
    "    idx_valid = current_index[valid_choices]\n",
    "    df_download['is_train'].loc[idx_valid] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_download['is_train'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this new dataframe\n",
    "df_download.to_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(CNN_TRAIN_IMAGE_DIR, 'train'), exist_ok=False)\n",
    "os.makedirs(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid'), exist_ok=False)\n",
    "\n",
    "labels = ['0', '1', '2']\n",
    "for l in labels:\n",
    "    os.makedirs(os.path.join(CNN_TRAIN_IMAGE_DIR, 'train', l), exist_ok=False)\n",
    "    os.makedirs(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', l), exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_download[df_download['is_train']]\n",
    "v = df_download[~df_download['is_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9320, 2330)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t), len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying train images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87b33ae3314e08ac50a51245c7d247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying valid images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d28ad631c5e44ce8581db9983f43a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uses symlinking to save disk space\n",
    "print('copying train images')\n",
    "for im_name, nl, country in tqdm(zip(t['image_name'], t['harvest_bin'], t['country']), total=len(t)):\n",
    "    country_dir = None\n",
    "    if country == 'mw':\n",
    "        country_dir = 'malawi_2016'\n",
    "    elif country == 'eth':\n",
    "        country_dir = 'ethiopia_2015'\n",
    "    elif country == 'ng':\n",
    "        country_dir = 'nigeria_2015'\n",
    "    else:\n",
    "        print(f\"no match for country {country}\")\n",
    "        raise ValueError()\n",
    "    src = os.path.abspath(os.path.join(COUNTRIES_DIR, country_dir, 'images', im_name))\n",
    "    dest = os.path.join(CNN_TRAIN_IMAGE_DIR, 'train', str(nl), im_name)\n",
    "    if os.symlink(src, dest, target_is_directory = False) != None:\n",
    "        print(\"error creating symlink\")\n",
    "        raise ValueError()\n",
    "\n",
    "print('copying valid images')\n",
    "for im_name, nl, country in tqdm(zip(v['image_name'], v['harvest_bin'], v['country']), total=len(v)):\n",
    "    country_dir = None\n",
    "    if country == 'mw':\n",
    "        country_dir = 'malawi_2016'\n",
    "    elif country == 'eth':\n",
    "        country_dir = 'ethiopia_2015'\n",
    "    elif country == 'ng':\n",
    "        country_dir = 'nigeria_2015'\n",
    "    else:\n",
    "        print(f\"no match for country {country}\")\n",
    "        raise ValueError()\n",
    "    src = os.path.abspath(os.path.join(COUNTRIES_DIR, country_dir, 'images', im_name))\n",
    "    dest = os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', str(nl), im_name)\n",
    "    if os.symlink(src, dest, target_is_directory = False) != None:\n",
    "        print(\"error creating symlink\")\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4880, 2000, 2440]\n",
      "[0.5236051502145923, 0.2145922746781116, 0.26180257510729615]\n",
      "9320\n"
     ]
    }
   ],
   "source": [
    "# shows count distribution in train folder, make sure this matches above\n",
    "counts = []\n",
    "for l in ['0', '1', '2']:\n",
    "    counts.append(len(os.listdir(os.path.join(CNN_TRAIN_IMAGE_DIR, 'train', l))))\n",
    "print(counts)\n",
    "print([c/sum(counts) for c in counts])\n",
    "print(sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1220, 500, 610]\n",
      "[0.5236051502145923, 0.2145922746781116, 0.26180257510729615]\n",
      "2330\n"
     ]
    }
   ],
   "source": [
    "# shows count distribution in valid folder\n",
    "counts = []\n",
    "for l in ['0', '1', '2']:\n",
    "    counts.append(len(os.listdir(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', l))))\n",
    "print(counts)\n",
    "print([c/sum(counts) for c in counts])\n",
    "print(sum(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "Heavily adapted from the PyTorch CNN training tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory.\n",
    "\n",
    "data_dir = CNN_TRAIN_IMAGE_DIR\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"vgg\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for, first 10 will be training the new layers, last 10 the whole model\n",
    "num_epochs = 2\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    input_size = 224\n",
    "    return model_ft, input_size\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can modify the classifier part of the model by doing this\n",
    "# model_ft.classifier = nn.Sequential(\n",
    "#     nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Linear(in_features=4096, out_features=256, bias=True),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Linear(in_features=256, out_features=3, bias=True),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        if epoch > 10:\n",
    "            # fine tune whole model\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.SGD(model_ft.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479dd479ca2b4f19a086d284240a622c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0017 Acc: 0.4848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f94fb869e6648cdbf8f0ae12b108bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.8130 Acc: 0.6382\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7d8a793414456b967f8bc5a0d6f749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8454 Acc: 0.6219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb43e141df564c7b9d315142ec8a1fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.7696 Acc: 0.6588\n",
      "\n",
      "Training complete in 3m 25s\n",
      "Best val Acc: 0.658824\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../models/trained_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/miniconda3/envs/omtest/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(CNN_SAVE_DIR, 'trained_model.pt')\n",
    "assert not os.path.isfile(path), print('A model is already saved at this location')\n",
    "print(f'Saving model to {path}')\n",
    "torch.save(model_ft, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8cf4f0f9ac42de96288e4f3bd0fea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6595, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# you can run below if you want to see the final accuracy on nightlights over the train set\n",
    "model_ft.eval()   # Set model to evaluate mode\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over data.\n",
    "for inputs, labels in tqdm(dataloaders_dict['train']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    total += len(preds)\n",
    "        \n",
    "print(running_corrects.double()/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "omtest",
   "language": "python",
   "name": "omtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
