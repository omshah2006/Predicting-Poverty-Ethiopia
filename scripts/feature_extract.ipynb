{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the images marked as valid per cluster, we pass them through the CNN and extract their feature vectors. the results are stored at a per-country basis. For example, all Malawi feature extractions will go into results/malawi_2016/cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "CNN_TRAIN_IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'cnn_images')\n",
    "CNN_DIR = os.path.join(BASE_DIR, 'models', 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "for country in ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']:\n",
    "    os.makedirs(os.path.join(RESULTS_DIR, country), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract with CNN\n",
    "If you have run this step before, you can skip it and run the commented out code in the next section to quick-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.09515_35.17229723579403_-17.09515_35.21721...</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.172297</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.11012192140199_35.217213_-17.09515_35.2172...</td>\n",
       "      <td>-17.110122</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.137266764205975_35.069727235794026_-17.092...</td>\n",
       "      <td>-17.137267</td>\n",
       "      <td>35.069727</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.062407157196017_35.09967107859801_-17.0923...</td>\n",
       "      <td>-17.062407</td>\n",
       "      <td>35.099671</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.062407157196017_35.114643_-17.092351_35.11...</td>\n",
       "      <td>-17.062407</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.09515_35.17229723579403_-17.09515_35.21721... -17.095150  35.172297   \n",
       "1  -17.11012192140199_35.217213_-17.09515_35.2172... -17.110122  35.217213   \n",
       "2  -17.137266764205975_35.069727235794026_-17.092... -17.137267  35.069727   \n",
       "3  -17.062407157196017_35.09967107859801_-17.0923... -17.062407  35.099671   \n",
       "4  -17.062407157196017_35.114643_-17.092351_35.11... -17.062407  35.114643   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "1   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "2   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "3   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "4   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "\n",
       "   is_train  \n",
       "0     False  \n",
       "1      True  \n",
       "2     False  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu as backend\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} as backend')\n",
    "model = torch.load(CNN_DIR, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rip off the final layers\n",
    "model.classifier = model.classifier[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ed31d0ad2c46e4929f5aac3b3d5a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb263b4e424d299cfebecb378abdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3144edbd0a44429a590759d033d11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# custom dataset for fast image loading and processing\n",
    "# does not follow the usual style of folder -> folder for each class -> image\n",
    "# we just want one folder with images\n",
    "class ForwardPassDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, transformer):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(self.image_dir)\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_list[index]\n",
    "\n",
    "        # Load image\n",
    "        X = self.filename_to_im_tensor(self.image_dir + '/' + image_name)\n",
    "        \n",
    "        # dataloaders need to return a label, but for the forward pass we don't really care\n",
    "        return X, -1\n",
    "    \n",
    "    def filename_to_im_tensor(self, file):\n",
    "        im = plt.imread(file)[:,:,:3]\n",
    "        im = self.transformer(im)\n",
    "        return im\n",
    "\n",
    "model.eval()  \n",
    "classes = [0, 1, 2]\n",
    "# shape of final array will be (num_validation_images, 4096)\n",
    "# we also want to record the image each index represents\n",
    "feats = np.zeros(((~df_images['is_train']).sum(), 4096))\n",
    "image_order = []\n",
    "i = 0\n",
    "for c in classes:\n",
    "    # use the validation images to do the forward pass\n",
    "    dataset = ForwardPassDataset(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', str(c)), transformer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "    image_order += dataset.image_list\n",
    "    # forward pass for this class\n",
    "    for inputs, _ in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        feats[i:i+len(inputs),:] = outputs.cpu().detach().numpy()\n",
    "        i += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40702829e-01,  2.01003835e-01,  8.64314213e-02, ...,\n",
       "         2.25341335e-01,  1.53573409e-01, -5.02701342e-01],\n",
       "       [ 2.13371171e-03,  5.38503230e-01,  1.76779941e-01, ...,\n",
       "         6.48638653e-03,  3.98272425e-01, -3.19114894e-01],\n",
       "       [-1.25464857e-01, -8.58640149e-02, -3.46169807e-04, ...,\n",
       "        -2.47483365e-02,  4.16845113e-01, -4.15563434e-01],\n",
       "       ...,\n",
       "       [-1.29724538e+00,  2.85363108e-01, -3.64852011e-01, ...,\n",
       "         8.64713937e-02,  4.76633519e-01, -6.36138201e-01],\n",
       "       [-8.12656507e-02,  2.53080100e-01,  1.45254254e-01, ...,\n",
       "        -7.83804506e-02,  2.39006728e-01, -5.38365543e-01],\n",
       "       [ 4.48328942e-01,  1.26719877e-01,  1.37911931e-01, ...,\n",
       "         6.94836676e-02,  3.76030467e-02, -6.82027221e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.585497910613984_7.626001672401992_5.55555406...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.633853237946016_7.287448788724023_4.66379708...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.891171405896015_7.981936444024024_4.92111524...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.403428078598008_35.14164692140199_-16.4184...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.791921820815976_7.318688398421992_4.74700605...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  feat_index\n",
       "0  5.585497910613984_7.626001672401992_5.55555406...           0\n",
       "1  4.633853237946016_7.287448788724023_4.66379708...           1\n",
       "2  4.891171405896015_7.981936444024024_4.92111524...           2\n",
       "3  -16.403428078598008_35.14164692140199_-16.4184...           3\n",
       "4  4.791921820815976_7.318688398421992_4.74700605...           4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass_df = pd.DataFrame.from_dict({'image_name': image_order, 'feat_index': np.arange(len(image_order))})\n",
    "forward_pass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumption = pd.merge(left=df_images, right=forward_pass_df, on='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have we maintained all validation images?\n",
    "assert len(df_consumption) == (~df_images['is_train']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>5.572374428973984_7.233412920995976_5.54243058...</td>\n",
       "      <td>5.572374</td>\n",
       "      <td>7.233413</td>\n",
       "      <td>5.542431</td>\n",
       "      <td>7.188497</td>\n",
       "      <td>4.360072</td>\n",
       "      <td>0.062247</td>\n",
       "      <td>ng</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>5.577058854163984_5.801921007398008_5.54711501...</td>\n",
       "      <td>5.577059</td>\n",
       "      <td>5.801921</td>\n",
       "      <td>5.547115</td>\n",
       "      <td>5.816893</td>\n",
       "      <td>9.504388</td>\n",
       "      <td>4.003194</td>\n",
       "      <td>ng</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>5.562086932761992_5.846836771603984_5.54711501...</td>\n",
       "      <td>5.562087</td>\n",
       "      <td>5.846837</td>\n",
       "      <td>5.547115</td>\n",
       "      <td>5.816893</td>\n",
       "      <td>9.504388</td>\n",
       "      <td>4.003194</td>\n",
       "      <td>ng</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>5.585497910613984_7.626001672401992_5.55555406...</td>\n",
       "      <td>5.585498</td>\n",
       "      <td>7.626002</td>\n",
       "      <td>5.555554</td>\n",
       "      <td>7.611030</td>\n",
       "      <td>4.462970</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>ng</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>5.600720432758885_7.335079439332507_5.56220655...</td>\n",
       "      <td>5.600720</td>\n",
       "      <td>7.335079</td>\n",
       "      <td>5.562207</td>\n",
       "      <td>7.340725</td>\n",
       "      <td>12.791067</td>\n",
       "      <td>0.110957</td>\n",
       "      <td>ng</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_name  image_lat  image_lon  \\\n",
       "335  5.572374428973984_7.233412920995976_5.54243058...   5.572374   7.233413   \n",
       "336  5.577058854163984_5.801921007398008_5.54711501...   5.577059   5.801921   \n",
       "337  5.562086932761992_5.846836771603984_5.54711501...   5.562087   5.846837   \n",
       "338  5.585497910613984_7.626001672401992_5.55555406...   5.585498   7.626002   \n",
       "339  5.600720432758885_7.335079439332507_5.56220655...   5.600720   7.335079   \n",
       "\n",
       "     cluster_lat  cluster_lon    cons_pc  nightlights country  \\\n",
       "335     5.542431     7.188497   4.360072     0.062247      ng   \n",
       "336     5.547115     5.816893   9.504388     4.003194      ng   \n",
       "337     5.547115     5.816893   9.504388     4.003194      ng   \n",
       "338     5.555554     7.611030   4.462970     0.013774      ng   \n",
       "339     5.562207     7.340725  12.791067     0.110957      ng   \n",
       "\n",
       "     nightlights_bin  is_train  feat_index  \n",
       "335                1     False         283  \n",
       "336                1     False         196  \n",
       "337                1     False         276  \n",
       "338                0     False           0  \n",
       "339                1     False         211  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_consumption.plot.scatter(x=\"nightlights_bin\", y=\"feat_index\")\n",
    "x = df_consumption['nightlights_bin']\n",
    "y = df_consumption['feat_index']\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features\n",
    "For each country, we aggregate the image features per cluster and save them to results/country/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_abbrv = ['mw', 'eth', 'ng']\n",
    "country_dir = ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']\n",
    "\n",
    "for ca, cd in zip(country_abbrv, country_dir):\n",
    "    df_c = df_consumption[df_consumption['country'] == ca]\n",
    "    group = df_c.groupby(['cluster_lat', 'cluster_lon'])\n",
    "    x = np.zeros((len(group), 4096))\n",
    "    cluster_list = [] # the corresponding clusters (lat, lon) to the x aggregate feature array\n",
    "    for i, g in enumerate(group):\n",
    "        lat, lon = g[0]\n",
    "        im_sub = df_consumption[(df_consumption['cluster_lat'] == lat) & (df_consumption['cluster_lon'] == lon)].reset_index(drop=True)\n",
    "        agg_feats = np.zeros((len(im_sub), 4096))\n",
    "        for j, d in im_sub.iterrows():\n",
    "            agg_feats[j,:] = feats[d.feat_index]\n",
    "        agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
    "\n",
    "        x[i,:] = agg_feats\n",
    "        cluster_list.append([lat, lon])\n",
    "    # save to the correct directory\n",
    "    save_dir = os.path.join(RESULTS_DIR, cd, 'cnn')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    np.save(os.path.join(save_dir, 'cluster_feats.npy'), x)\n",
    "    pickle.dump(cluster_list, open(os.path.join(save_dir, 'cluster_order.pkl'), 'wb')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "omtest",
   "language": "python",
   "name": "omtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
